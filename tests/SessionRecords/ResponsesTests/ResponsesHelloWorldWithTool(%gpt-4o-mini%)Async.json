{
  "Entries": [
    {
      "RequestUri": "https://api.openai.com/v1/responses",
      "RequestMethod": "POST",
      "RequestHeaders": {
        "Accept": "application/json, text/event-stream",
        "Authorization": "Sanitized",
        "Content-Length": "399",
        "Content-Type": "application/json",
        "User-Agent": "OpenAI/2.2.0 (.NET 9.0.7; Microsoft Windows 10.0.26100)"
      },
      "RequestBody": {
        "model": "gpt-4o-mini",
        "input": [
          {
            "type": "message",
            "role": "user",
            "content": [
              {
                "type": "input_text",
                "text": "good morning, responses!"
              }
            ]
          }
        ],
        "truncation": "auto",
        "tools": [
          {
            "type": "function",
            "name": "get_custom_greeting",
            "description": "invoked when user provides a typical greeting",
            "strict": false,
            "parameters": {
              "type": "object",
              "properties": {
                "time_of_day": {
                  "type": "string"
                }
              }
            }
          }
        ]
      },
      "StatusCode": 200,
      "ResponseHeaders": {
        "Alt-Svc": "h3=\":443\"",
        "cf-cache-status": "DYNAMIC",
        "CF-RAY": "9682ee347ae675a8-SEA",
        "Connection": "keep-alive",
        "Content-Length": "1618",
        "Content-Type": "application/json",
        "Date": "Fri, 01 Aug 2025 05:28:10 GMT",
        "openai-organization": "Sanitized",
        "openai-processing-ms": "825",
        "openai-project": "Sanitized",
        "openai-version": "2020-10-01",
        "Server": "cloudflare",
        "Strict-Transport-Security": "max-age=31536000; includeSubDomains; preload",
        "X-Content-Type-Options": "nosniff",
        "x-envoy-decorator-operation": "tasksapi.openai.svc.cluster.local:8081/*",
        "x-envoy-upstream-service-time": "833",
        "x-ratelimit-limit-requests": "30000",
        "x-ratelimit-limit-tokens": "150000000",
        "x-ratelimit-remaining-requests": "29999",
        "x-ratelimit-remaining-tokens": "149999735",
        "x-ratelimit-reset-requests": "2ms",
        "x-ratelimit-reset-tokens": "0s",
        "X-Request-ID": "Sanitized"
      },
      "ResponseBody": {
        "id": "resp_688c5069b8f8819a907fd15106b073730bb89600d6fb5786",
        "object": "response",
        "created_at": 1754026089,
        "status": "completed",
        "background": false,
        "error": null,
        "incomplete_details": null,
        "instructions": null,
        "max_output_tokens": null,
        "max_tool_calls": null,
        "model": "gpt-4o-mini-2024-07-18",
        "output": [
          {
            "id": "fc_688c506a5bb0819ab9808ac3b9e56c8d0bb89600d6fb5786",
            "type": "function_call",
            "status": "completed",
            "arguments": "{\"time_of_day\":\"morning\"}",
            "call_id": "call_Ha6i7T5qqZ9XvyWMRX7iljeo",
            "name": "get_custom_greeting"
          }
        ],
        "parallel_tool_calls": true,
        "previous_response_id": null,
        "prompt_cache_key": null,
        "reasoning": {
          "effort": null,
          "summary": null
        },
        "safety_identifier": null,
        "service_tier": "default",
        "store": true,
        "temperature": 1.0,
        "text": {
          "format": {
            "type": "text"
          }
        },
        "tool_choice": "auto",
        "tools": [
          {
            "type": "function",
            "description": "invoked when user provides a typical greeting",
            "name": "get_custom_greeting",
            "parameters": {
              "type": "object",
              "properties": {
                "time_of_day": {
                  "type": "string"
                }
              }
            },
            "strict": false
          }
        ],
        "top_logprobs": 0,
        "top_p": 1.0,
        "truncation": "auto",
        "usage": {
          "input_tokens": 48,
          "input_tokens_details": {
            "cached_tokens": 0
          },
          "output_tokens": 20,
          "output_tokens_details": {
            "reasoning_tokens": 0
          },
          "total_tokens": 68
        },
        "user": null,
        "metadata": {}
      }
    }
  ],
  "Variables": {}
}
